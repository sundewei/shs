<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <title>SAP Hadoop MapReduce Example (Log Processing)</title>
    <link href="../../css/codesite.pack.04102009.css" type="text/css" rel="stylesheet">
    <script type="text/javascript" src="../../../resources/js/jquery.js"></script>
    <script type="text/javascript" src="../../js/common.js"></script>
</head>

<body class="gc-documentation">

<style type='text/css'>
img.screen {
 width: 800px ;
 height: 600px;
 border-style:solid;
 border-width:1px;
 border-color:#98bf21;
}
</style>

<div id="gc-container">

<!-- start gc-topnav -->
<div id="gc-topnav">
    <h1>SAP Hadoop MapReduce Example (Log Processing)</h1>
    <ul id="docs" class="gc-topnav-tabs">
    </ul>
</div>
<script type="text/javascript">
    $("ul#docs").html(getTopNavTabHtml());
    $("#logProcessing").addClass("selected");
</script>
<!-- end gc-topnav -->

<div class="g-section g-tpl-170">

<div class="g-unit g-first" id="gc-toc">
    <ul>
        <li><h2>Quick Links</h2>
            <ul>
                <li>
                    <a href="#Introduction" title="Introduction">Introduction</a>
                </li>

                <li>
                    <a href="#Prerequisites1" title="Prerequisites1">Prerequisites 1</a>
                </li>

                <li>
                    <a href="#Prerequisites2" title="Prerequisites2">Prerequisites 2</a>
                </li>

                <li>
                    <a href="#RunTheMapReduceExample" title="Run The MapReduce Example">Run the MapReduce Example</a>
                </li>

                <li>
                    <a href="#TheLogProcessingLogic" title="The Log Processing Logic">The Log Processing Logic</a>
                </li>

                <li>
                    <a href="#FindingTheProductTrend" title="Finding The Product Trend">Finding The Product Trend</a>
                </li>

                <li>
                    <a href="#Conclusion" title="Conclusion">Conclusion</a>
                </li>

            </ul>
        </li>
    </ul>

</div>

<a name="gc-pagecontent-anchor"></a>

<div class="g-unit" id="gc-pagecontent">

<a name="Introduction"></a>

<h1>Introduction</h1>
<p>
    If you have arrived this page, that means you have certain understanding about Hadoop.  Now let's focus on a relatively common usage -- Log Processing.
    <br /><br />
    The log files used in this example are in the format used by Apache Web Server and Apache Tomcat Application Server.
    <br /><br />
    If you wish to parse different log files in different format, please change the MapReduce source code accordingly.
</p>

<a name="Prerequisites1"></a>

<h1>Prerequisites 1</h1>

<p>
    <ul class="bulletlist">
        <li> The MapReduce code for this example is compressed as a JAR file and stored on the HDFS.<br/> Please download <a href="sap_hadoop_example.jar" target="_new">sap_hadoop_example.jar</a> to your local folder, for example: c:\hadoop_example\ </li>
        <li> Download one or more sample dated input log files (<a href="localhost_access_log.2011-08-01.txt" target="_new">2011-08-01.txt</a>, <a href="localhost_access_log.2011-08-02.txt" target="_new">2011-08-02.txt</a>, <a href="localhost_access_log.2011-08-03.txt" target="_new">2011-08-03.txt</a>, <a href="localhost_access_log.2011-08-04.txt" target="_new">2011-08-04.txt</a>) to your local folder, for example: c:\hadoop_example\ (You need at least one log file to run the example)</li>
        <li> (Optional) Request access to SAP Hadoop cluster by sending your employee ID to <a href="mailto:dewei.sun@sap.com">me</a> or you can just use the test account coded in the example source</li>
    </ul>
    <br />
    Please contact <a href="mailto:dewei.sun@sap.com">Dewei Sun</a>, if there is any error opening above links.
</p>

<a name="Prerequisites2"></a>

<h1>Prerequisites 2</h1>

<p>
    If you wish to modify the code and parse your own log, then please do the following steps after completing Prerequisites 1.
    <ul class="bulletlist">
        <li> Install JDK 1.6 or higher from <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_new">here</a></li>
        <li> Install Apache Ant and setup your ANT_HOME environment variable and add ANT_HOME\bin to your PATH environment variable, guidelines can be found <a href="http://ant.apache.org/" target="_new">here</a>. </li>
        <li> Download the compressed code lab <a href="LogProcessingExample.zip" target="_new"></a> and uncompress it to your local harddrive, for example, if you uncompress it under C:\, then a folder will be created as C:\LogProcessingExample\</li>
        <li> Make sure you can build/compile by opening a Command Prompt and type in "ant" after changing to the new folder created by above step, for example: C:\LogProcessingExample\</li>
    </ul>
    <br />
    Please contact <a href="mailto:dewei.sun@sap.com">Dewei Sun</a>, if there is any error opening above links.
</p>

<a name="RunTheMapReduceExample"></a>

<h1>Run the MapReduce Example</h1>

<p>
    1. Upload the sample log files to your HDFS personal folder or the visitor HDFS folder (I123456/hadoopsap) via <a href="http://hadoop.pal.sap.corp:8080/shs/jspv/dashboard.jsp" target="_new">Task Force</a> Web Application.

    <br /><br />

    <img src="UploadLogs1.png" class="screen" />

    <br /><br />

    <img src="UploadLogs2.png" class="screen" />

    <br /><br />

    <img src="UploadLogs3.png" class="screen" />

    <br /><br />
    In case you need some guidelines about how to use <a href="http://hadoop.pal.sap.corp:8080/shs/jspv/dashboard.jsp" target="_new">Task Force</a> Web Application, please refer to <a href="http://hadoop.pal.sap.corp:8080/shs/doc/codeLabShs.html" target="_new">code lab 2</a>.
    <br /><br />
    2. Go to the "Submit a Task" tab in <a href="http://hadoop.pal.sap.corp:8080/shs/jspv/dashboard.jsp" target="_new">Task Force</a> and upload the sap_hadoop_example.jar.

    <br /><br />

    <img src="UploadJar1.png" class="screen" />

    <br /><br />

    3. Select "com.sap.mapred.LogProcessingExample" in the "MapReduce Class" drop down list and enter the HDFS directory containing the log files, for example: /user/I123456/

    <br /><br />

    <img src="UploadJar2.png" class="screen" />

    <br /><br />

    4. Go to Hadoop's <a href="http://llnpal055:50030/jobtracker.jsp" target="_new">Task Status</a> page and make sure you see your 2 jobs have completed (AccessLogParser and ProductTrend).
    <br /><br />
    There will be 2 jobs running once you have done Step 3, the first job will be displayed in Task Force but the second job is not shown by Task Force and can only be checked manually in via Hadoop Job Status page using the job id.

    <br /><br />

    <img src="Finished2Jobs.png" class="screen" />

    <br /><br />

    5. You can view the result of the log processing result, please fo to HDFS <a href="http://llnpal055:50070/dfshealth.jsp" target="_new">status page</a> and click on "Browse the filesystem" to preview/download the result file called "part-r-00000", for example: /user/I123456/parsed/trend/part-r-00000.

    <br /><br />

    <img src="LogResultOnHDFS1.png" class="screen" />

    <br /><br />

    <img src="LogResultOnHDFS2.png" class="screen" />

    <br /><br />

<a name="TheLogProcessingLogic"></a>

<h1>The Log Processing Logic</h1>

<p>
    <strong>1. Access Log Format</strong>

    <br /><br />

    The Apache Web/Tomcat Application Server access log is generated in the following format:

    <br/><br/>

    <pre>
        <code>
<font color="blue">198.93.34.21 - frank [02/Aug/2011:00:00:01 -0700] "GET /Antec-EA-380D-Power-Supply/dp/B002UOR17Y/ HTTP/1.1" 200 7577</font>
169.145.89.205 - - [02/Aug/2011:00:00:03 -0700] "GET /Antec-EA-380D-Power-Supply/dp/B002UOR17Y/ HTTP/1.1" 200 247
198.93.34.21 - - [02/Aug/2011:00:00:04 -0700] "GET /Michelin-Pilot-Road-Rear-Tire/dp/B004MDSTW2/ HTTP/1.1" 200 102
198.93.34.21 - - [02/Aug/2011:00:00:06 -0700] "GET /Razor-Wild-Style-Kick-Scooter/dp/B002S0YPUG/ HTTP/1.1" 200 833
10.48.58.42 - - [02/Aug/2011:00:00:08 -0700] "GET /Peg-Perego-Polaris-Outlaw-Pink/dp/B003JI62HU/ HTTP/1.1" 200 561
        </code>
    </pre>

    <br /><br />

    A typical configuration for the access log might look as follows.

    <br /><br />

    <font color="red">%h %l %u %t \"%r\" %>s %b</font>

    <br /><br />

    Each part of this log entry is described below.

    <br /><br />

    <font color="blue">198.93.34.21 (%h)</font>
    <br />
    This is the IP address of the client (remote host) which made the request to the server. If HostnameLookups is set to On, then the server will try to determine the hostname and log it in place of the IP address. However, this configuration is not recommended since it can significantly slow the server. Instead, it is best to use a log post-processor such as logresolve to determine the hostnames. The IP address reported here is not necessarily the address of the machine at which the user is sitting. If a proxy server exists between the user and the server, this address will be the address of the proxy, rather than the originating machine.

    <br /><br />

    <font color="blue">- (%l)</font>
    <br />
    The "hyphen" in the output indicates that the requested piece of information is not available. In this case, the information that is not available is the RFC 1413 identity of the client determined by identd on the clients machine. This information is highly unreliable and should almost never be used except on tightly controlled internal networks. Apache httpd will not even attempt to determine this information unless IdentityCheck is set to On.

    <br /><br />

    <font color="blue">frank (%u)</font>
    <br />
    This is the userid of the person requesting the document as determined by HTTP authentication. The same value is typically provided to CGI scripts in the REMOTE_USER environment variable. If the status code for the request (see below) is 401, then this value should not be trusted because the user is not yet authenticated. If the document is not password protected, this part will be "-" just like the previous one.

    <br /><br />

    <font color="blue">[02/Aug/2011:00:00:01 -0700] (%t)</font>
    <br />
    The time that the request was received. The format is:
    [day/month/year:hour:minute:second zone]
    day = 2*digit
    month = 3*letter
    year = 4*digit
    hour = 2*digit
    minute = 2*digit
    second = 2*digit
    zone = (`+' | `-') 4*digit

    <br /><br />

    <font color="blue">"GET /Antec-EA-380D-Power-Supply/dp/B002UOR17Y/ HTTP/1.0" (\"%r\")</font>
    <br />
    The request line from the client is given in double quotes. The request line contains a great deal of useful information. First, the method used by the client is GET. Second, the client requested the resource /apache_pb.gif, and third, the client used the protocol HTTP/1.0. It is also possible to log one or more parts of the request line independently. For example, the format string "%m %U%q %H" will log the method, path, query-string, and protocol, resulting in exactly the same output as "%r".

    <br /><br />

    <font color="blue">200 (%>s)</font>
    <br />
    This is the status code that the server sends back to the client. This information is very valuable, because it reveals whether the request resulted in a successful response (codes beginning in 2), a redirection (codes beginning in 3), an error caused by the client (codes beginning in 4), or an error in the server (codes beginning in 5). The full list of possible status codes can be found in the HTTP specification (RFC2616 section 10).

    <br /><br />

    <font color="blue">7577 (%b)</font>
    <br />
    The last part indicates the size of the object returned to the client, not including the response headers. If no content was returned to the client, this value will be "-". To log "0" for no content, use %B instead.

    <br /><br />

    <strong>2. Parsing lines in the Access Log (The LogParser's Map Method)</strong>

    <br /><br />

    The code to parse each line of log into an inner class "AccessData" is in LogParser.java as following, please see the code comments for details.

    <br /><br />

    <pre>
        <code>
private static AccessData getAccessData(String line) {
    <font color=grey>// An AccessData object will be created for each line if possible</font>
    AccessData accessData = null;

    try {
        accessData = new AccessData();
        <font color=grey>// Parse the value separated line using space as the delimiter</font>
        CSVParser csvParser = new CSVParser(new StringReader(line));
        csvParser.getStrategy().setDelimiter(' ');

        <font color=grey>// Now get all the values from the line</font>
        String[] values = csvParser.getLine();

        <font color=grey>// Get the IP</font>
        accessData.ip = values[0];

        <font color=grey>// The time is split into 2 values so they have to be combined</font>
        <font color=grey>// then sent to match the time regular expression</font>
        <font color=grey>// "[02/Aug/2011:00:00:04" + " -0700]" = "[02/Aug/2011:00:00:04 -0700]"</font>
        accessData.timestamp = new Timestamp(DATA_FORMAT.parse(values[3] + " " + values[4]).getTime());

        <font color=grey>// The resource filed has 3 fields (HTTP Method, Page and HTTP protocol)</font>
        <font color=grey>// so it has to be further split by spaces</font>
        String reqInfo = values[5];
        String[] reqInfoArr = reqInfo.split(" ");

        <font color=grey>// Get the HTTP method</font>
        accessData.method = reqInfoArr[0];

        <font color=grey>// Get the page requested</font>
        accessData.resource = reqInfoArr[1];

        <font color=grey>// Get the HTTP response code</font>
        accessData.httpCode = Integer.parseInt(values[6]);

        <font color=grey>// Try to get the response data size in bytes, if a hyphen shows up,</font>
        <font color=grey>// that means the client has a cache of this page and no data is</font>
        <font color=grey>// sent back</font>
        try {
            accessData.dataLength = Long.parseLong(values[7]);
        } catch (NumberFormatException nfe) {
            accessData.dataLength = 0;
        }

        return accessData;
    } catch (IOException ioe) {
        LOG.info(ioe);
        return null;
    } catch (ParseException pe) {
        LOG.info(pe);
        return null;
    }
}
        </code>
    </pre>

    <br /><br />

    <strong>3. Group the AccessData Objects by IP (The LogParser's Reduce Method)</strong>

    <br /><br />

    Among all AccessData objects parsed from the access log lines, we need to build the browsing history for each distinct IP so the products an IP visited are ordered ascendingly by their timestamps in millisecond.

    <br /><br />

    The <strong>italic</strong> text below is a line of the LogParser's Reduce method output:

    <br /><br />

    <pre>
        <code>
<i>10.48.101.113	<font color=blue>1312182008000_B000PKZ8EI</font>,<font color=black>1312182008450_B004MDSTW2</font>,<font color=green>1312182011000_B0015AARJI</font>,<font color=red>1312182011000_B003AUF1XI</font></i>

       |                    |                        |                        |                        |

      IP              First Product            Second Product           Third Product            Forth Product
        </code>
    </pre>

    <br /><br />

    The output of LogParser MapReduce code is a normalized form of users' access history, it can be used for multiple business cases like fraud detection, ad targeting, user profiling and product tracking.

    <br /><br />

    In the business cases mentioned above, the LogParser usually is scheduled to run on the past N days' access log file periodically and its output then be fed to other MapReduce as inputs.

    <br /><br />

    Our next MapReduce code included in this example will be focusing on finding the most visited products after any given given product.

    <br /><br />

</p>

<a name="FindingTheProductTrend"></a>

<h1>Finding the Product Trend</h1>

<p>

    <strong>1. Product Trend Map Method</strong>

    <br /><br />

    The output of the LogParser is users' browsing history and now we need to find the most popular products after a given product is visited.

    <br /><br />

    To do this, we need to read the LogParser's output line by line and to find all pairs of 2 contiguous products when their visit times are within a reasonable interval.

    <br /><br />

    This is the basically logic of the ProductTrend's map method and below is its sample output:

    <br /><br />

    <pre>
        <code>
B000PKZ8EI    B004MDSTW2
B004MDSTW2    B0015AARJI
B000PKZ8EI    B004MDSTW2
B0015AARJI    B003AUF1XI
B000PKZ8EI    B004MDSTW2
B0015AARJI    B003AUF1XI
        </code>
    </pre>

    <br /><br />

    <strong>2. Product Trend Reduce Method</strong>

    <br /><br />

    Now for each first product id, the reduce method would get the second product counts and generate percentages of the second products.

    <br /><br />

    Also, in order to make it more user-readable, there is another iteration to replace the product id to product name.

    <br /><br />

    The output would look like this:

    <br /><br />

    <pre>
        <code>
Sony BRAVIA KDL 46V5100 46 Inch 1080p,18.50%	,Panasonic VIERA TC P50G25 50 Inch Plasma
Sony BRAVIA KDL 46V5100 46 Inch 1080p,13.26%	,VIZIO XVT373SV 37 Inch Internet Application
Sony BRAVIA KDL 46V5100 46 Inch 1080p,08.07%	,LG 37LV3500 Accessory Cables Cleaning
Sony BRAVIA KDL 46V5100 46 Inch 1080p,06.00%	,Canon T2i Digital 3 0 Inch 18 55mm
PlayStation 3 160GB System,27.66%	,PlayStation Dualshock Wireless Controller Black 3
PlayStation 3 160GB System,14.24%	,Halo Combat Evolved Anniversary Xbox 360
PlayStation 3 160GB System,13.13%	,Xbox 360 Gears Limited Console Bundle
Canon T3i Digital Imaging 18 55mm,19.46%	,Canon T2i Digital 3 0 Inch 18 55mm
Canon T3i Digital Imaging 18 55mm,07.93%	,Canon 55 250mm 4 0 5 6 Telephoto Digital
Canon T3i Digital Imaging 18 55mm,06.36%	,Razor Aggressive Youth Multi sport Helmet
Canon T3i Digital Imaging 18 55mm,06.13%	,Michelin Pilot Road Rear Tire
Canon T3i Digital Imaging 18 55mm,05.65%	,Michael Antonio Womens Theronn Platform
Canon T3i Digital Imaging 18 55mm,05.61%	,PlayStation Dualshock Wireless Controller Black 3
Canon T3i Digital Imaging 18 55mm,05.50%	,AmazonBasics Lens Pen Cleaning System
Michael Antonio Womens Dress Shoes,11.79%	,Michael Antonio Womens Theronn Platform
Michael Antonio Womens Dress Shoes,09.48%	,Loreal Colour Lipstick 415 Cherry
Michael Antonio Womens Dress Shoes,07.67%	,Razor Aggressive Youth Multi sport Helmet
Michael Antonio Womens Dress Shoes,07.30%	,PlayStation Dualshock Wireless Controller Black 3
Michael Antonio Womens Dress Shoes,05.57%	,Intex Recreation Giant 59252EP Inflatable
        </code>
    </pre>

    <br /><br />

    Now this result can be used for generating a recommendation list for in every product page to increase sales revenue.
</p>

<a name="Conclusion"></a>

<h1>Conclusion</h1>

<p>
    The ProductTrend MapReduce logic is relatively easier than LogParser and more like statistics but the LogParser would provide the basic input for many business cases.  With Hadoop's support, now-a-days enterprises can find useful information from huge non-related data and optimize their business accordingly.

    <br /><br />
    For further coding exercise, please read though the code and add/modify ProductTrend to find users who have been visiting more than 20 products in 3 seconds.
</p>

</div>
<!-- end gc-pagecontent -->
</div>
<!-- end gooey wrapper -->
</div>
<!-- end codesite content -->
<div id="gc-footer" dir="ltr">
    <div class="text">
        ©2011 SAP
    </div>
</div>
<!-- end gc-footer -->

</body>
</html>

